{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\nimport yaml\n\n# !mkdir \"/kaggle/working/labels\"\n# !cp -r \"/kaggle/input/car-plate-detection/images\" \"/kaggle/working/images\"","metadata":{"execution":{"iopub.status.busy":"2022-10-30T16:14:20.987993Z","iopub.execute_input":"2022-10-30T16:14:20.988545Z","iopub.status.idle":"2022-10-30T16:14:29.460172Z","shell.execute_reply.started":"2022-10-30T16:14:20.988454Z","shell.execute_reply":"2022-10-30T16:14:29.459042Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"imgs = os.listdir('/kaggle/working/images')\nimgs_train, imgs_val = train_test_split(imgs, test_size=0.05)\n\ndf = pd.read_csv('../input/car-plate-get-annotation-info-from-xml/annotation.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-30T16:14:29.462424Z","iopub.execute_input":"2022-10-30T16:14:29.462672Z","iopub.status.idle":"2022-10-30T16:14:29.484585Z","shell.execute_reply.started":"2022-10-30T16:14:29.462643Z","shell.execute_reply":"2022-10-30T16:14:29.483823Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# —Ä–∞–∑–º–µ—Ä—ã –æ–±—É—á–∞—é—â–µ–π/—Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–æ–∫\nlen(imgs_train), len(imgs_val)","metadata":{"execution":{"iopub.status.busy":"2022-10-30T17:10:18.222104Z","iopub.execute_input":"2022-10-30T17:10:18.222404Z","iopub.status.idle":"2022-10-30T17:10:18.227945Z","shell.execute_reply.started":"2022-10-30T17:10:18.222371Z","shell.execute_reply":"2022-10-30T17:10:18.227098Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(411, 22)"},"metadata":{}}]},{"cell_type":"code","source":"cwd = '/kaggle/working/'\ndata = dict(\n    train =  cwd + 'train.txt',\n    val   =  cwd + 'val.txt',\n    lr0 = 0.1,\n    nc    = 1,\n    names = ['licence'],\n)\n# .yaml —Ñ–∞–π–ª —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ —Å–µ—Ç–∏\nwith open(cwd + 'bgr.yaml', 'w') as outfile:\n    yaml.dump(data, outfile, default_flow_style=False)\n    \n# –∞–Ω–æ—Ç–∞—Ü–∏–∏ –¥–ª—è —Ç—Ä–µ–π–Ω–∞\nwith open(cwd + 'train.txt', 'w') as f:\n    for path in imgs_train:\n        f.write(cwd + 'images/' + path + '\\n')\n# –∞–Ω–æ—Ç–∞—Ü–∏–∏ –¥–ª—è —Ç–µ—Å—Ç–∞\nwith open(cwd + 'val.txt', 'w') as f:\n    for path in imgs_val:\n        f.write(cwd + 'images/' + path + '\\n')","metadata":{"execution":{"iopub.status.busy":"2022-10-30T18:02:36.494067Z","iopub.execute_input":"2022-10-30T18:02:36.494365Z","iopub.status.idle":"2022-10-30T18:02:36.504179Z","shell.execute_reply.started":"2022-10-30T18:02:36.494331Z","shell.execute_reply":"2022-10-30T18:02:36.503407Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"for file in imgs:\n    file = file.split('.')[0]\n    bboxs = []\n    for _,row in df[df['file'] == file].iterrows():\n        bbox = [str(0), str(row['Xcent']), str(row['Ycent']), str(row['boxW']), str(row['boxH'])]\n        bbox = ' '.join(bbox)\n        bboxs.append(bbox)\n    with open(cwd + 'labels/' + file + '.txt', 'w') as f:\n        bboxs = '\\n'.join(bboxs)\n        f.write(bboxs)","metadata":{"execution":{"iopub.status.busy":"2022-10-30T16:14:51.997472Z","iopub.execute_input":"2022-10-30T16:14:51.997980Z","iopub.status.idle":"2022-10-30T16:14:52.299328Z","shell.execute_reply.started":"2022-10-30T16:14:51.997943Z","shell.execute_reply":"2022-10-30T16:14:52.298652Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Model for Object Detection (License Detection) ‚Äì YOLOv5","metadata":{}},{"cell_type":"code","source":"# –∫–ª–æ–Ω–∏—Ä—É–µ–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π —Å yolov5\n!git clone https://github.com/ultralytics/yolov5\n%cd yolov5\n%pip install -qr requirements.txt","metadata":{"execution":{"iopub.status.busy":"2022-10-30T21:21:36.119164Z","iopub.execute_input":"2022-10-30T21:21:36.119454Z","iopub.status.idle":"2022-10-30T21:21:46.747344Z","shell.execute_reply.started":"2022-10-30T21:21:36.119421Z","shell.execute_reply":"2022-10-30T21:21:46.746344Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Cloning into 'yolov5'...\nremote: Enumerating objects: 14570, done.\u001b[K\nremote: Counting objects: 100% (140/140), done.\u001b[K\nremote: Compressing objects: 100% (73/73), done.\u001b[K\nremote: Total 14570 (delta 86), reused 112 (delta 67), pack-reused 14430\u001b[K\nReceiving objects: 100% (14570/14570), 13.44 MiB | 22.79 MiB/s, done.\nResolving deltas: 100% (10064/10064), done.\n/kaggle/working/yolov5/yolov5\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"!python train.py --img 1280\\\n--batch 8\\\n--epochs 50\\\n--optimizer SGD\\\n--data /kaggle/working/bgr.yaml\\\n--weights yolov5m6.pt\\\n--name result_1280_8_50_SGD","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-10-30T16:17:19.588063Z","iopub.execute_input":"2022-10-30T16:17:19.588377Z","iopub.status.idle":"2022-10-30T17:09:10.452687Z","shell.execute_reply.started":"2022-10-30T16:17:19.588341Z","shell.execute_reply":"2022-10-30T17:09:10.451809Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manony-mouse-429839\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5m6.pt, cfg=, data=/kaggle/working/bgr.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=50, batch_size=8, imgsz=1280, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=result_1280_8_50_SGD, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ‚úÖ\nYOLOv5 üöÄ v6.2-216-g6e544d5 Python-3.7.12 torch-1.9.1 CUDA:0 (Tesla P100-PCIE-16GB, 16281MiB)\n\n\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\n\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.4\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/yolov5/wandb/run-20221030_161729-22eb4kmd\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mresult_1280_8_50_SGD\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/anony-mouse-429839/YOLOv5?apiKey=205c431e32d07306eece8822f93a0fb16246fd3d\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/anony-mouse-429839/YOLOv5/runs/22eb4kmd?apiKey=205c431e32d07306eece8822f93a0fb16246fd3d\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Do NOT share these links with anyone. They can be used to claim your runs.\nDownloading https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5m6.pt to yolov5m6.pt...\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 69.0M/69.0M [00:01<00:00, 38.7MB/s]\n\nOverriding model.yaml nc=80 with nc=1\n\n                 from  n    params  module                                  arguments                     \n  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n  7                -1  1   1991808  models.common.Conv                      [384, 576, 3, 2]              \n  8                -1  2   2327040  models.common.C3                        [576, 576, 2]                 \n  9                -1  1   3982848  models.common.Conv                      [576, 768, 3, 2]              \n 10                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n 11                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n 12                -1  1    443520  models.common.Conv                      [768, 576, 1, 1]              \n 13                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 14           [-1, 8]  1         0  models.common.Concat                    [1]                           \n 15                -1  2   2658816  models.common.C3                        [1152, 576, 2, False]         \n 16                -1  1    221952  models.common.Conv                      [576, 384, 1, 1]              \n 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 18           [-1, 6]  1         0  models.common.Concat                    [1]                           \n 19                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n 20                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n 21                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 22           [-1, 4]  1         0  models.common.Concat                    [1]                           \n 23                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n 24                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n 25          [-1, 20]  1         0  models.common.Concat                    [1]                           \n 26                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n 27                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n 28          [-1, 16]  1         0  models.common.Concat                    [1]                           \n 29                -1  2   2437632  models.common.C3                        [768, 576, 2, False]          \n 30                -1  1   2987136  models.common.Conv                      [576, 576, 3, 2]              \n 31          [-1, 12]  1         0  models.common.Concat                    [1]                           \n 32                -1  2   4429824  models.common.C3                        [1152, 768, 2, False]         \n 33  [23, 26, 29, 32]  1     34632  models.yolo.Detect                      [1, [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], [192, 384, 576, 768]]\nModel summary: 379 layers, 35275944 parameters, 35275944 gradients, 49.3 GFLOPs\n\nTransferred 619/627 items from yolov5m6.pt\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 103 weight(decay=0.0), 107 weight(decay=0.0005), 107 bias\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/kaggle/working/train' images and labels...411 found, 0 missing\u001b[0m\n\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/train.cache\n\u001b[34m\u001b[1mval: \u001b[0mScanning '/kaggle/working/val' images and labels...22 found, 0 missing, 0 e\u001b[0m\n\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/val.cache\n\n\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.80 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\nPlotting labels to runs/train/result_1280_8_50_SGD/labels.jpg... \nImage sizes 1280 train, 1280 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mruns/train/result_1280_8_50_SGD\u001b[0m\nStarting training for 50 epochs...\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       0/49      11.9G    0.09588    0.04587          0          4       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23     0.0231      0.739     0.0483     0.0125\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       1/49      12.2G     0.0749    0.02924          0         18       1280:  train.py:319: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n  torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)  # clip gradients\n       1/49      12.2G    0.06804    0.02567          0         10       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.108      0.696      0.229     0.0754\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       2/49      12.2G    0.06313    0.01911          0         10       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.369      0.522      0.491      0.171\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       3/49      12.2G    0.05787    0.01759          0          6       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.321      0.652      0.349      0.154\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       4/49      12.2G    0.04945    0.01593          0          7       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.514      0.478      0.593       0.31\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       5/49      12.2G    0.04703    0.01367          0          1       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23       0.43      0.522      0.465      0.205\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       6/49      12.2G    0.04516    0.01198          0          3       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.713      0.649      0.751      0.372\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       7/49      12.2G    0.04127    0.01103          0          5       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.709      0.826      0.771       0.46\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       8/49      12.2G    0.03999    0.01138          0          6       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.737      0.739      0.753       0.42\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       9/49      12.2G    0.03841    0.01036          0          5       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.892      0.913        0.9      0.495\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      10/49      12.2G    0.03665    0.00918          0          5       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23       0.95      0.834       0.92      0.567\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      11/49      12.2G    0.03572   0.008674          0          5       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.855      0.769      0.821      0.491\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      12/49      12.2G    0.03518   0.008263          0          6       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.869      0.869      0.904      0.494\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      13/49      12.2G    0.03348   0.008711          0          3       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.803      0.913      0.868      0.476\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      14/49      12.2G    0.03315   0.008272          0          8       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23       0.82      0.913      0.867      0.553\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      15/49      12.2G    0.03296   0.008054          0          5       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.836      0.913      0.886      0.522\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      16/49      12.2G    0.03213   0.008376          0          5       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.882      0.913      0.908      0.511\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      17/49      12.2G    0.03084   0.007808          0          7       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.829       0.87      0.817      0.515\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      18/49      12.2G     0.0301   0.007713          0          7       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.867      0.913      0.918       0.54\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      19/49      12.2G    0.02907   0.007507          0          5       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23       0.91      0.913        0.9      0.603\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      20/49      12.2G    0.02839   0.007684          0          5       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.871      0.913      0.898      0.543\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      21/49      12.2G    0.02797   0.007203          0          3       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.946      0.913      0.945      0.561\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      22/49      12.2G    0.02776   0.007493          0          5       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.863       0.87      0.862      0.516\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      23/49      12.2G    0.02826   0.007015          0          5       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.854      0.783      0.852      0.552\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      24/49      12.2G    0.02647   0.007353          0          6       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.905      0.825      0.899      0.581\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      25/49      12.2G    0.02543   0.006588          0          3       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23       0.95      0.829      0.889      0.551\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      26/49      12.2G    0.02669   0.006867          0          7       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23       0.91      0.826        0.9      0.552\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      27/49      12.2G    0.02485   0.006724          0          7       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.867       0.87      0.895      0.576\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      28/49      12.2G      0.025   0.006648          0          9       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.951      0.957      0.945      0.523\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      29/49      12.2G    0.02399   0.007124          0          8       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.909      0.913      0.896      0.574\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      30/49      12.2G    0.02356   0.006501          0          7       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.948      0.913      0.905      0.568\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      31/49      12.2G    0.02376   0.006632          0          7       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.912      0.904      0.867      0.525\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      32/49      12.2G    0.02323   0.006933          0          7       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.904      0.913      0.867      0.542\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      33/49      12.2G    0.02265   0.006533          0          3       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.954      0.908      0.942      0.545\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      34/49      12.2G     0.0222   0.006466          0          6       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23        0.9      0.826      0.869      0.555\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      35/49      12.2G    0.02094   0.006275          0          2       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.904      0.821      0.843      0.563\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      36/49      12.2G    0.02146    0.00618          0          6       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.909      0.868      0.869      0.524\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      37/49      12.2G    0.02096    0.00609          0          4       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.947      0.826      0.891       0.55\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      38/49      12.2G    0.02042   0.006147          0          7       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.955      0.913      0.907      0.541\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      39/49      12.2G     0.0198   0.005935          0         11       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.943       0.87      0.896       0.56\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      40/49      12.2G    0.01982   0.005824          0          3       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.989      0.913       0.95       0.58\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      41/49      12.2G    0.01939   0.006125          0          9       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.952      0.867      0.896      0.615\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      42/49      12.2G    0.01891   0.005875          0          6       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.952      0.864      0.906      0.646\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      43/49      12.2G    0.01871    0.00602          0          5       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.943      0.913      0.909      0.618\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      44/49      12.2G    0.01786   0.005768          0          2       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.946      0.913      0.901      0.598\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      45/49      12.2G    0.01879   0.005821          0          7       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.944      0.913      0.898      0.595\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      46/49      12.2G     0.0176   0.005659          0          6       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.931      0.913      0.904      0.609\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      47/49      12.2G    0.01796   0.006235          0          7       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.905      0.913        0.9      0.608\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      48/49      12.2G    0.01787   0.005869          0          4       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.947       0.87       0.89      0.602\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      49/49      12.2G     0.0168   0.005632          0          5       1280: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.946       0.87       0.89      0.596\n\n50 epochs completed in 0.845 hours.\nOptimizer stripped from runs/train/result_1280_8_50_SGD/weights/last.pt, 71.8MB\nOptimizer stripped from runs/train/result_1280_8_50_SGD/weights/best.pt, 71.8MB\n\nValidating runs/train/result_1280_8_50_SGD/weights/best.pt...\nFusing layers... \nModel summary: 276 layers, 35248920 parameters, 0 gradients, 48.9 GFLOPs\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.952      0.864      0.906      0.646\nResults saved to \u001b[1mruns/train/result_1280_8_50_SGD\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Artifacts logged anonymously cannot be claimed and expire after 7 days.\n\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: \n\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà\n\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ‚ñÖ‚ñÑ‚ñÅ‚ñÉ‚ñÅ‚ñÉ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá\n\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ‚ñà‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ\n\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ\n\u001b[34m\u001b[1mwandb\u001b[0m: \n\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 42\n\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.90597\n\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.64602\n\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.95207\n\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.86381\n\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.90584\n\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.6459\n\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.95207\n\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.86394\n\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.0168\n\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0\n\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.00563\n\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.02791\n\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.0\n\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.00416\n\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.0005\n\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.0005\n\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.0005\n\u001b[34m\u001b[1mwandb\u001b[0m: \n\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mresult_1280_8_50_SGD\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/anony-mouse-429839/YOLOv5/runs/22eb4kmd?apiKey=205c431e32d07306eece8822f93a0fb16246fd3d\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 315 media file(s), 1 artifact file(s) and 0 other file(s)\n\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20221030_161729-22eb4kmd/logs\u001b[0m\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9236833a70>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1262, in _shutdown_workers\nAttributeError: 'NoneType' object has no attribute 'python_exit_status'\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9236833a70>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1262, in _shutdown_workers\nAttributeError: 'NoneType' object has no attribute 'python_exit_status'\n","output_type":"stream"}]},{"cell_type":"code","source":"!python train.py --img 1280\\\n--batch 8\\\n--epochs 100\\\n--optimizer SGD\\\n--data /kaggle/working/bgr.yaml\\\n--weights yolov5m6.pt\\\n--name result_1280_8_50_SGD_01","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python train.py --img 640\\\n--batch 8\\\n--epochs 50\\\n--optimizer Adam\\\n--data /kaggle/working/bgr.yaml\\\n--weights yolov5m6.pt\\\n--name result_640_8_50_Adam","metadata":{"execution":{"iopub.status.busy":"2022-10-30T20:26:04.030414Z","iopub.execute_input":"2022-10-30T20:26:04.030797Z","iopub.status.idle":"2022-10-30T20:49:10.443876Z","shell.execute_reply.started":"2022-10-30T20:26:04.030754Z","shell.execute_reply":"2022-10-30T20:49:10.442971Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manony-mouse-429839\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5m6.pt, cfg=, data=/kaggle/working/bgr.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=50, batch_size=8, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=Adam, sync_bn=False, workers=8, project=runs/train, name=result_640_8_50_Adam, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ‚úÖ\nYOLOv5 üöÄ v6.2-216-g6e544d5 Python-3.7.12 torch-1.9.1 CUDA:0 (Tesla P100-PCIE-16GB, 16281MiB)\n\n\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\n\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.4\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/yolov5/wandb/run-20221030_202611-42j2dhek\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mresult_640_8_50_Adam\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/anony-mouse-429839/YOLOv5?apiKey=205c431e32d07306eece8822f93a0fb16246fd3d\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/anony-mouse-429839/YOLOv5/runs/42j2dhek?apiKey=205c431e32d07306eece8822f93a0fb16246fd3d\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Do NOT share these links with anyone. They can be used to claim your runs.\nOverriding model.yaml nc=80 with nc=1\n\n                 from  n    params  module                                  arguments                     \n  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n  7                -1  1   1991808  models.common.Conv                      [384, 576, 3, 2]              \n  8                -1  2   2327040  models.common.C3                        [576, 576, 2]                 \n  9                -1  1   3982848  models.common.Conv                      [576, 768, 3, 2]              \n 10                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n 11                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n 12                -1  1    443520  models.common.Conv                      [768, 576, 1, 1]              \n 13                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 14           [-1, 8]  1         0  models.common.Concat                    [1]                           \n 15                -1  2   2658816  models.common.C3                        [1152, 576, 2, False]         \n 16                -1  1    221952  models.common.Conv                      [576, 384, 1, 1]              \n 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 18           [-1, 6]  1         0  models.common.Concat                    [1]                           \n 19                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n 20                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n 21                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 22           [-1, 4]  1         0  models.common.Concat                    [1]                           \n 23                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n 24                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n 25          [-1, 20]  1         0  models.common.Concat                    [1]                           \n 26                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n 27                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n 28          [-1, 16]  1         0  models.common.Concat                    [1]                           \n 29                -1  2   2437632  models.common.C3                        [768, 576, 2, False]          \n 30                -1  1   2987136  models.common.Conv                      [576, 576, 3, 2]              \n 31          [-1, 12]  1         0  models.common.Concat                    [1]                           \n 32                -1  2   4429824  models.common.C3                        [1152, 768, 2, False]         \n 33  [23, 26, 29, 32]  1     34632  models.yolo.Detect                      [1, [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], [192, 384, 576, 768]]\nModel summary: 379 layers, 35275944 parameters, 35275944 gradients, 49.3 GFLOPs\n\nTransferred 619/627 items from yolov5m6.pt\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.01) with parameter groups 103 weight(decay=0.0), 107 weight(decay=0.0005), 107 bias\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/kaggle/working/train.cache' images and labels... 411 found, 0 \u001b[0m\n\u001b[34m\u001b[1mval: \u001b[0mScanning '/kaggle/working/val.cache' images and labels... 22 found, 0 missi\u001b[0m\n\n\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.96 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\nPlotting labels to runs/train/result_640_8_50_Adam/labels.jpg... \nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mruns/train/result_640_8_50_Adam\u001b[0m\nStarting training for 50 epochs...\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       0/49      3.61G    0.08598    0.01323          0         19        640:  train.py:319: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n  torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)  # clip gradients\n       0/49      3.64G    0.08521    0.01304          0          4        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23          0          0          0          0\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       1/49      5.45G     0.0801    0.01334          0         19        640:  train.py:319: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n  torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)  # clip gradients\n       1/49      5.45G    0.07938     0.0133          0         10        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23          0          0          0          0\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       2/49      5.45G    0.07924    0.01269          0         16        640:  train.py:319: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n  torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)  # clip gradients\n       2/49      5.45G     0.0797    0.01278          0         10        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23          0          0          0          0\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       3/49      5.45G    0.07853    0.01281          0          6        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23          0          0          0          0\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       4/49      5.45G    0.08025    0.01224          0         15        640:  train.py:319: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n  torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)  # clip gradients\n       4/49      5.45G     0.0763    0.01297          0          7        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23          0          0          0          0\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       5/49      5.45G    0.07682    0.01237          0         14        640:  train.py:319: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n  torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)  # clip gradients\n       5/49      5.45G     0.0781    0.01189          0          1        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23          0          0          0          0\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       6/49      5.45G    0.07281    0.01222          0          3        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.135       0.13     0.0684     0.0216\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       7/49      5.45G    0.07567    0.01165          0          5        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.191       0.13      0.123     0.0429\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       8/49      5.45G    0.07803    0.01241          0          6        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23     0.0308      0.174     0.0231     0.0103\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       9/49      5.45G    0.07618    0.01175          0          5        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23     0.0237      0.348     0.0188     0.0054\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      10/49      5.45G    0.07813    0.01161          0          5        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.312      0.217      0.225      0.089\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      11/49      5.45G    0.07418    0.01107          0          5        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.322      0.217      0.225     0.0893\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      12/49      5.45G    0.06802    0.01124          0          6        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.181      0.217     0.0825     0.0305\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      13/49      5.45G    0.06974    0.01176          0          3        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.156      0.304       0.13     0.0334\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      14/49      5.45G    0.07058    0.01225          0          8        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.187      0.261      0.114      0.018\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      15/49      5.45G    0.06498    0.01219          0          5        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23     0.0186      0.174     0.0125    0.00236\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      16/49      5.45G     0.0656    0.01276          0          5        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.457      0.174      0.187     0.0466\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      17/49      5.45G    0.06234    0.01179          0          7        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.255      0.304      0.153     0.0334\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      18/49      5.45G    0.06472    0.01186          0          7        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.233      0.174      0.148     0.0289\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      19/49      5.45G    0.06364    0.01177          0          5        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.258      0.227      0.116     0.0317\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      20/49      5.45G    0.06151    0.01221          0          5        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.256      0.304      0.228     0.0835\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      21/49      5.45G    0.06124    0.01126          0          3        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.242      0.217       0.15     0.0704\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      22/49      5.45G    0.06104     0.0119          0          5        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.193      0.261      0.242     0.0808\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      23/49      5.45G    0.05873    0.01121          0          5        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.329      0.304       0.26     0.0582\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      24/49      5.45G    0.06399    0.01196          0          6        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.463      0.174      0.281     0.0905\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      25/49      5.45G    0.05555    0.01087          0          3        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.535      0.217      0.261     0.0877\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      26/49      5.45G    0.05725    0.01125          0          7        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23       0.41      0.261      0.321      0.105\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      27/49      5.45G    0.05749    0.01113          0          7        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.479      0.304      0.353      0.124\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      28/49      5.45G    0.05863     0.0112          0          9        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.311      0.304      0.204     0.0774\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      29/49      5.45G     0.0568    0.01136          0          8        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.342      0.304      0.287      0.117\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      30/49      5.45G    0.05387    0.01103          0          7        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.452      0.261       0.39      0.112\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      31/49      5.45G    0.05468    0.01111          0          7        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23       0.36      0.478      0.368      0.167\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      32/49      5.45G    0.05604    0.01211          0          7        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.248      0.301       0.24      0.079\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      33/49      5.45G    0.05492    0.01153          0          3        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.411      0.455      0.338      0.132\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      34/49      5.45G    0.05664    0.01123          0          6        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23        0.4      0.349      0.431       0.21\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      35/49      5.45G    0.05038     0.0112          0          3        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.645      0.238      0.299      0.115\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      36/49      5.45G    0.05286    0.01143          0          6        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.466      0.391        0.4      0.187\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      37/49      5.45G    0.05057    0.01127          0          4        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.438      0.391      0.461      0.168\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      38/49      5.45G    0.05138    0.01084          0          7        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23       0.77      0.391      0.459      0.156\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      39/49      5.45G    0.05311    0.01107          0         11        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.626       0.51       0.51      0.171\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      40/49      5.45G    0.05196    0.01104          0          3        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.425      0.435      0.404      0.166\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      41/49      5.45G    0.04954    0.01094          0          9        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.373      0.696      0.437      0.161\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      42/49      5.45G    0.04784    0.01067          0          7        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.446      0.435      0.447      0.218\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      43/49      5.45G    0.04878    0.01096          0          5        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.742      0.478      0.588        0.3\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      44/49      5.45G     0.0486    0.01028          0          2        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.783      0.472      0.571      0.222\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      45/49      5.45G    0.04771    0.01013          0          7        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.681      0.435      0.591      0.271\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      46/49      5.45G    0.04813    0.01028          0          6        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.593      0.609      0.572      0.257\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      47/49      5.45G    0.04508    0.01096          0          7        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.725      0.478      0.615      0.303\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      48/49      5.45G    0.04754    0.01029          0          4        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.644      0.435      0.579      0.282\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      49/49      5.45G    0.04597    0.01031          0          5        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.749      0.519      0.661      0.324\n\n50 epochs completed in 0.373 hours.\nOptimizer stripped from runs/train/result_640_8_50_Adam/weights/last.pt, 71.2MB\nOptimizer stripped from runs/train/result_640_8_50_Adam/weights/best.pt, 71.2MB\n\nValidating runs/train/result_640_8_50_Adam/weights/best.pt...\nFusing layers... \nModel summary: 276 layers, 35248920 parameters, 0 gradients, 48.9 GFLOPs\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.749      0.519       0.66      0.324\nResults saved to \u001b[1mruns/train/result_640_8_50_Adam\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Artifacts logged anonymously cannot be claimed and expire after 7 days.\n\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: \n\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà\n\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñà\n\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñà‚ñá‚ñÑ‚ñÖ‚ñà‚ñà‚ñÜ‚ñá‚ñá‚ñà\n\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÜ\n\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ\n\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ‚ñá‚ñà‚ñá‚ñá‚ñÖ‚ñÜ‚ñÑ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÅ\n\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss      ‚ñà‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss      ‚ñà‚ñÉ‚ñÜ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ\n\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ\n\u001b[34m\u001b[1mwandb\u001b[0m: \n\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 49\n\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.66064\n\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.32382\n\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.74889\n\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.51885\n\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.66046\n\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.3236\n\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.74889\n\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.51885\n\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.04597\n\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0\n\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.01031\n\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.04625\n\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.0\n\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.0052\n\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.0005\n\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.0005\n\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.0005\n\u001b[34m\u001b[1mwandb\u001b[0m: \n\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mresult_640_8_50_Adam\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/anony-mouse-429839/YOLOv5/runs/42j2dhek?apiKey=205c431e32d07306eece8822f93a0fb16246fd3d\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 285 media file(s), 1 artifact file(s) and 0 other file(s)\n\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20221030_202611-42j2dhek/logs\u001b[0m\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f240abc3a70>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1262, in _shutdown_workers\nAttributeError: 'NoneType' object has no attribute 'python_exit_status'\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f240abc3a70>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1262, in _shutdown_workers\nAttributeError: 'NoneType' object has no attribute 'python_exit_status'\n","output_type":"stream"}]},{"cell_type":"code","source":"!python train.py --img 640\\\n--batch 8\\\n--epochs 50\\\n--optimizer SGD\\\n--data /kaggle/working/bgr.yaml\\\n--weights yolov5m6.pt\\\n--name result_640_8_50_SGD","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python train.py --img 640\\\n--batch 8\\\n--epochs 50\\\n--optimizer AdamW\\\n--data /kaggle/working/bgr.yaml\\\n--weights yolov5m6.pt\\\n--name result_640_8_50_AdamW","metadata":{"execution":{"iopub.status.busy":"2022-10-30T20:49:30.757936Z","iopub.execute_input":"2022-10-30T20:49:30.758232Z","iopub.status.idle":"2022-10-30T21:12:41.316095Z","shell.execute_reply.started":"2022-10-30T20:49:30.758202Z","shell.execute_reply":"2022-10-30T21:12:41.315218Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manony-mouse-429839\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5m6.pt, cfg=, data=/kaggle/working/bgr.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=50, batch_size=8, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=AdamW, sync_bn=False, workers=8, project=runs/train, name=result_640_8_50_AdamW, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\nremote: Enumerating objects: 16, done.\u001b[K\nremote: Counting objects: 100% (16/16), done.\u001b[K\nremote: Compressing objects: 100% (13/13), done.\u001b[K\nremote: Total 16 (delta 9), reused 4 (delta 3), pack-reused 0\u001b[K\nUnpacking objects: 100% (16/16), 10.31 KiB | 1.29 MiB/s, done.\nFrom https://github.com/ultralytics/yolov5\n * [new branch]      glenn-jocher-patch-2 -> origin/glenn-jocher-patch-2\n\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ‚úÖ\nYOLOv5 üöÄ v6.2-216-g6e544d5 Python-3.7.12 torch-1.9.1 CUDA:0 (Tesla P100-PCIE-16GB, 16281MiB)\n\n\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\n\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.4\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/yolov5/wandb/run-20221030_204937-122dj5b0\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mresult_640_8_50_AdamW\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/anony-mouse-429839/YOLOv5?apiKey=205c431e32d07306eece8822f93a0fb16246fd3d\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/anony-mouse-429839/YOLOv5/runs/122dj5b0?apiKey=205c431e32d07306eece8822f93a0fb16246fd3d\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Do NOT share these links with anyone. They can be used to claim your runs.\nOverriding model.yaml nc=80 with nc=1\n\n                 from  n    params  module                                  arguments                     \n  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n  7                -1  1   1991808  models.common.Conv                      [384, 576, 3, 2]              \n  8                -1  2   2327040  models.common.C3                        [576, 576, 2]                 \n  9                -1  1   3982848  models.common.Conv                      [576, 768, 3, 2]              \n 10                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n 11                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n 12                -1  1    443520  models.common.Conv                      [768, 576, 1, 1]              \n 13                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 14           [-1, 8]  1         0  models.common.Concat                    [1]                           \n 15                -1  2   2658816  models.common.C3                        [1152, 576, 2, False]         \n 16                -1  1    221952  models.common.Conv                      [576, 384, 1, 1]              \n 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 18           [-1, 6]  1         0  models.common.Concat                    [1]                           \n 19                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n 20                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n 21                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 22           [-1, 4]  1         0  models.common.Concat                    [1]                           \n 23                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n 24                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n 25          [-1, 20]  1         0  models.common.Concat                    [1]                           \n 26                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n 27                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n 28          [-1, 16]  1         0  models.common.Concat                    [1]                           \n 29                -1  2   2437632  models.common.C3                        [768, 576, 2, False]          \n 30                -1  1   2987136  models.common.Conv                      [576, 576, 3, 2]              \n 31          [-1, 12]  1         0  models.common.Concat                    [1]                           \n 32                -1  2   4429824  models.common.C3                        [1152, 768, 2, False]         \n 33  [23, 26, 29, 32]  1     34632  models.yolo.Detect                      [1, [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], [192, 384, 576, 768]]\nModel summary: 379 layers, 35275944 parameters, 35275944 gradients, 49.3 GFLOPs\n\nTransferred 619/627 items from yolov5m6.pt\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.01) with parameter groups 103 weight(decay=0.0), 107 weight(decay=0.0005), 107 bias\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/kaggle/working/train.cache' images and labels... 411 found, 0 \u001b[0m\n\u001b[34m\u001b[1mval: \u001b[0mScanning '/kaggle/working/val.cache' images and labels... 22 found, 0 missi\u001b[0m\n\n\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.96 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\nPlotting labels to runs/train/result_640_8_50_AdamW/labels.jpg... \nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mruns/train/result_640_8_50_AdamW\u001b[0m\nStarting training for 50 epochs...\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       0/49      3.61G    0.09074    0.01341          0         20        640:  train.py:319: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n  torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)  # clip gradients\n       0/49      3.64G    0.08903    0.01282          0          4        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23          0          0          0          0\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       1/49      5.45G    0.08448    0.01325          0         10        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23          0          0          0          0\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       2/49      5.45G     0.0855    0.01283          0         16        640:  train.py:319: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n  torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)  # clip gradients\n       2/49      5.45G    0.08582    0.01292          0         10        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23          0          0          0          0\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       3/49      5.45G    0.08854    0.01305          0         21        640:  train.py:319: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n  torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)  # clip gradients\n       3/49      5.45G    0.09026    0.01299          0         21        640:  train.py:319: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n  torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)  # clip gradients\n       3/49      5.45G    0.08904    0.01296          0          6        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23          0          0          0          0\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       4/49      5.45G    0.08434    0.01303          0          7        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23          0          0          0          0\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       5/49      5.45G    0.08368    0.01239          0          1        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23          0          0          0          0\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       6/49      5.45G    0.07865    0.01228          0          3        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.005     0.0435    0.00418   0.000837\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       7/49      5.45G    0.07836    0.01158          0          5        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.102      0.217     0.0504    0.00831\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       8/49      5.45G    0.08255    0.01238          0          6        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.184      0.304      0.166     0.0461\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       9/49      5.45G    0.07904    0.01215          0          5        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.268      0.217      0.183     0.0305\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      10/49      5.45G    0.08366    0.01141          0          5        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.325      0.252      0.225     0.0795\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      11/49      5.45G    0.07995    0.01086          0          5        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.329      0.304      0.212     0.0744\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      12/49      5.45G    0.07658    0.01093          0          6        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.362      0.198      0.163     0.0342\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      13/49      5.45G    0.07766    0.01161          0          3        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.425      0.261      0.235     0.0833\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      14/49      5.45G    0.07929    0.01171          0          8        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.327       0.13      0.177     0.0671\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      15/49      5.45G     0.0745    0.01113          0          5        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.247      0.217      0.232     0.0851\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      16/49      5.45G     0.0773    0.01166          0          5        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.302      0.217      0.184     0.0519\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      17/49      5.45G    0.07153    0.01106          0          7        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.423      0.261       0.26     0.0812\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      18/49      5.45G    0.07381    0.01127          0          7        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.313      0.217      0.176     0.0657\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      19/49      5.45G    0.07071    0.01164          0          5        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.649      0.217        0.3      0.117\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      20/49      5.45G    0.07242    0.01142          0          5        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.382      0.261      0.315      0.134\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      21/49      5.45G    0.07024    0.01102          0          3        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.403      0.304      0.311      0.185\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      22/49      5.45G    0.07007    0.01153          0          5        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.465      0.261      0.308      0.129\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      23/49      5.45G    0.06904    0.01075          0          5        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.629       0.13      0.203     0.0911\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      24/49      5.45G    0.07814    0.01163          0          6        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.224      0.376      0.287      0.142\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      25/49      5.45G    0.06551    0.01042          0          3        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.335      0.348      0.244     0.0835\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      26/49      5.45G    0.06484    0.01081          0          7        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.588      0.304      0.348      0.137\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      27/49      5.45G    0.06623     0.0107          0          7        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.549      0.391      0.422      0.126\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      28/49      5.45G    0.07332    0.01067          0          9        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.276      0.348       0.25     0.0733\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      29/49      5.45G    0.06902    0.01137          0          8        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.395      0.304      0.288      0.105\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      30/49      5.45G    0.06857    0.01067          0          7        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.553      0.304      0.398      0.183\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      31/49      5.45G    0.06678    0.01099          0          7        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.509      0.522      0.503       0.22\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      32/49      5.45G    0.06887    0.01177          0          7        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.426      0.348      0.384      0.161\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      33/49      5.45G    0.06916     0.0111          0          3        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23       0.54      0.391      0.366      0.136\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      34/49      5.45G       0.07    0.01101          0          6        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.492      0.565      0.405      0.173\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      35/49      5.45G    0.06256    0.01078          0          3        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.442      0.435      0.417      0.173\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      36/49      5.45G    0.06649    0.01082          0          6        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.452      0.611      0.448        0.2\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      37/49      5.45G    0.06209    0.01099          0          4        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.499      0.478      0.472      0.165\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      38/49      5.45G    0.06606    0.01082          0          7        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23       0.54      0.478      0.492      0.185\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      39/49      5.45G    0.06693    0.01087          0         11        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.542      0.565      0.617      0.265\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      40/49      5.45G    0.06369     0.0108          0          3        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.619      0.496      0.498      0.223\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      41/49      5.45G    0.06105    0.01066          0          9        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.477      0.522      0.465      0.165\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      42/49      5.45G    0.06042    0.01062          0          7        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.546      0.627      0.519      0.165\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      43/49      5.45G    0.06401    0.01087          0          5        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.656      0.435      0.526      0.203\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      44/49      5.45G     0.0627    0.01029          0          2        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.575      0.478      0.466      0.183\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      45/49      5.45G    0.06254    0.01018          0          7        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.618      0.435      0.501      0.268\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      46/49      5.45G    0.06431    0.01041          0          6        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.518      0.565      0.508      0.226\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      47/49      5.45G    0.05958    0.01119          0          7        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.471      0.739      0.568      0.273\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      48/49      5.45G    0.06368    0.01054          0          4        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.671      0.478      0.519      0.251\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      49/49      5.45G    0.06263    0.01061          0          5        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.451      0.571      0.531      0.263\n\n50 epochs completed in 0.375 hours.\nOptimizer stripped from runs/train/result_640_8_50_AdamW/weights/last.pt, 71.2MB\nOptimizer stripped from runs/train/result_640_8_50_AdamW/weights/best.pt, 71.2MB\n\nValidating runs/train/result_640_8_50_AdamW/weights/best.pt...\nFusing layers... \nModel summary: 276 layers, 35248920 parameters, 0 gradients, 48.9 GFLOPs\n                 Class     Images  Instances          P          R      mAP50   \n                   all         22         23      0.471      0.739      0.568      0.272\nResults saved to \u001b[1mruns/train/result_640_8_50_AdamW\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Artifacts logged anonymously cannot be claimed and expire after 7 days.\n\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: \n\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá\n\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÉ‚ñÖ‚ñÉ‚ñÖ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñà\n\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñÖ‚ñÖ‚ñà‚ñÉ‚ñÑ‚ñá‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñà‚ñÜ\n\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñà\n\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss ‚ñà‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ\n\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÇ\n\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss       ‚ñà‚ñá‚ñà‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ\n\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss       ‚ñá‚ñÖ‚ñÜ‚ñÉ‚ñÑ‚ñá ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÖ‚ñÇ‚ñÉ‚ñÇ‚ñà‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ\n\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ\n\u001b[34m\u001b[1mwandb\u001b[0m: \n\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 47\n\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.56785\n\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.27305\n\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.47094\n\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.73913\n\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.56788\n\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.27219\n\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.47095\n\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.73913\n\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.06263\n\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0\n\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.01061\n\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.06289\n\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.0\n\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.0051\n\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.0005\n\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.0005\n\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.0005\n\u001b[34m\u001b[1mwandb\u001b[0m: \n\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mresult_640_8_50_AdamW\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/anony-mouse-429839/YOLOv5/runs/122dj5b0?apiKey=205c431e32d07306eece8822f93a0fb16246fd3d\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 285 media file(s), 1 artifact file(s) and 0 other file(s)\n\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20221030_204937-122dj5b0/logs\u001b[0m\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb50a740a70>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1262, in _shutdown_workers\nAttributeError: 'NoneType' object has no attribute 'python_exit_status'\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb50a740a70>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1262, in _shutdown_workers\nAttributeError: 'NoneType' object has no attribute 'python_exit_status'\n","output_type":"stream"}]}]}